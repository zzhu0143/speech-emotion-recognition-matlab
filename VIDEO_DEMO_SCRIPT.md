# Video Demonstration Script

**Project:** Speech Emotion Recognition Using MATLAB Deep Learning
**Course:** ELEC5305 - Speech and Audio Processing
**Duration:** 5-10 minutes
**Student:** Zhu

---

## Video Recording Guidelines

### Before Recording

**Equipment:**
- Screen recording software (OBS Studio, Camtasia, or MATLAB's built-in screen capture)
- Microphone for voice-over
- MATLAB R2020b+ with all required toolboxes installed
- RAVDESS dataset downloaded and extracted

**Preparation:**
- Close unnecessary applications
- Set MATLAB to full screen or large window
- Increase font size in MATLAB for visibility
- Prepare sample audio files for demonstration
- Have trained models ready (or train before recording)

### Recording Tips
- Speak clearly and at moderate pace
- Pause briefly between sections
- Point out important parts of code/results
- Show both successes and explain any issues

---

## Script Outline (8-10 minutes)

### 1. Introduction (1 minute)

**[Screen: Title slide or GitHub repository page]**

"Hello, my name is Zhu, and this is my ELEC5305 project demonstration on Speech Emotion Recognition using MATLAB Deep Learning.

In this video, I'll show you:
- The project overview and objectives
- How the code works
- A live demonstration of training and prediction
- Key results and findings

Let's get started."

---

### 2. Project Overview (1 minute)

**[Screen: Show README.md on GitHub or project folder structure]**

"This project implements an emotion recognition system that classifies 8 different emotional states from speech: neutral, calm, happy, sad, angry, fearful, disgust, and surprised.

The system uses the RAVDESS dataset, which contains high-quality emotional speech recordings from 24 actors.

I've implemented two deep learning models:
1. A baseline feedforward neural network
2. An LSTM network that captures temporal patterns in speech

The code is organized into modular MATLAB files, making it easy to understand and reuse."

**[Screen: Show project folder structure]**

---

### 3. Code Walkthrough (2-3 minutes)

**[Screen: Open main_train_all_models.m in MATLAB]**

#### 3.1 Main Training Pipeline

"Let me walk you through the main training script. This is `main_train_all_models.m`, which orchestrates the entire pipeline.

**[Scroll through code, highlighting key sections]**

First, we load the RAVDESS dataset using the `loadRAVDESSData` function.

**[Open loadRAVDESSData.m briefly]**

This function:
- Scans the RAVDESS directory structure
- Parses filenames to extract emotion labels
- Returns audio file paths and corresponding labels

**[Return to main script]**

Next, we extract audio features. Let me show you the feature extraction function."

**[Open extractAudioFeatures.m]**

"This function extracts 95-dimensional features including:
- MFCCs (Mel-Frequency Cepstral Coefficients) - the most important features
- Spectral features like centroid and rolloff
- Temporal features like zero-crossing rate
- Pitch statistics

These features capture both the frequency and temporal characteristics of emotional speech."

**[Return to main script]**

#### 3.2 Model Training

"The script then trains two models. Let me open the baseline model training function."

**[Open trainBaselineModel.m]**

"This creates a feedforward neural network with:
- Multiple fully connected layers
- Batch normalization for stable training
- Dropout for regularization
- Adam optimizer with learning rate scheduling

The LSTM model is similar but uses recurrent layers to capture temporal dynamics."

---

### 4. Live Demonstration (3-4 minutes)

**[Screen: MATLAB Command Window, ready to run]**

#### 4.1 Running the Training

"Now let's run the actual training. I'll execute the main script."

**[Type and run:]**
```matlab
cd('C:\path\to\speech_emotion_recognition_matlab')
main_train_all_models
```

"As you can see, the script is now:
1. Loading the dataset - we have 1,440 audio samples from 24 actors
2. Extracting features - this takes about 10-15 minutes, but I've pre-extracted them
3. Splitting data into training and testing sets

**[Show training progress window when it appears]**

The training progress window shows:
- Training loss decreasing over epochs
- Validation accuracy improving
- This gives us confidence the model is learning

**[Note: If training takes too long, use pre-trained models and explain:]**

For this demo, I'll use pre-trained models to save time, but the training process typically takes 30-50 minutes for both models."

#### 4.2 Examining Results

**[Screen: Show generated confusion matrices]**

"Here are the confusion matrices for both models.

**[Point to baseline confusion matrix]**

The baseline model achieves around 75-80% accuracy. We can see:
- Strong diagonal (correct predictions)
- Some confusion between similar emotions like Calm and Sad
- Good performance on distinct emotions like Angry and Happy

**[Point to LSTM confusion matrix]**

The LSTM model performs better at 82-88% accuracy because it captures temporal patterns in speech. Notice the darker diagonal and fewer misclassifications."

**[Show model comparison figure if available]**

"This comparison shows the LSTM outperforms the baseline, confirming that temporal information is crucial for emotion recognition."

#### 4.3 Real-time Prediction Demo

**[Screen: MATLAB Command Window]**

"Now let's test the prediction on a real audio file."

**[Type and run:]**
```matlab
% Load a test audio file
audioFile = 'data/RAVDESS/Actor_01/03-01-05-01-01-01-01.wav';

% The filename tells us this is "angry" emotion
% Let's see if our model can predict it correctly

[emotion, probs] = predictEmotion(audioFile, 'models/lstm_model.mat');

fprintf('Predicted Emotion: %s\n', emotion);
fprintf('Confidence: %.2f%%\n', max(probs) * 100);
```

**[Show results]**

"Excellent! The model correctly predicted 'angry' with XX% confidence.

Let me show you the probability distribution across all emotions:"

**[Run:]**
```matlab
% Display all probabilities
emotionNames = {'neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprised'};
figure;
bar(probs);
set(gca, 'XTickLabel', emotionNames);
title('Emotion Probability Distribution');
ylabel('Probability');
xtickangle(45);
```

**[Show the bar chart]**

"As you can see, 'angry' has the highest probability, with some probability assigned to 'fearful' - which makes sense as these emotions share some acoustic characteristics."

**[Optional: Test another file with different emotion]**

---

### 5. Key Findings and Results (1-2 minutes)

**[Screen: Summary slide or MATLAB figure window]**

"Let me summarize the key findings:

**Performance:**
- Baseline model: 75-80% accuracy
- LSTM model: 82-88% accuracy
- The LSTM's ability to capture temporal patterns gives it a 5-8% improvement

**Feature Importance:**
- MFCCs are the most discriminative features
- Temporal dynamics matter - static features alone aren't sufficient
- Pitch and energy features help distinguish arousal levels

**Challenges:**
- Calm and Sad are often confused (similar low-energy profiles)
- Fear and Surprise are sometimes mixed (both high-arousal)
- Dataset balance affects performance

**Practical Applications:**
- Customer service sentiment analysis
- Mental health monitoring
- Human-computer interaction
- Entertainment and gaming"

---

### 6. Conclusion and Future Work (1 minute)

**[Screen: GitHub repository or final results]**

"To conclude, this project successfully implemented a speech emotion recognition system achieving over 80% accuracy using MATLAB's Deep Learning Toolbox.

The key contributions are:
1. A complete, modular implementation suitable for further research
2. Comparison of feedforward vs. recurrent architectures
3. Comprehensive documentation for reproducibility

**Future improvements could include:**
- Data augmentation to improve robustness
- CNN-LSTM hybrid architecture for even better performance
- Real-time processing for live applications
- Cross-dataset validation
- Attention mechanisms to identify important temporal segments

**All code is available on GitHub:**
https://github.com/zzhu0143/speech-emotion-recognition-matlab

The repository includes:
- Complete source code
- Detailed README with installation instructions
- Full research report
- This demonstration video

Thank you for watching. If you have questions, please feel free to reach out through GitHub or university email."

---

## Recording Checklist

Before recording, ensure:

- [ ] MATLAB is open with increased font size
- [ ] Project directory is set as current folder
- [ ] Dataset is downloaded and in correct location
- [ ] Models are trained (or pre-trained models ready)
- [ ] Sample audio files identified for demo
- [ ] Screen recorder is configured (1080p minimum)
- [ ] Microphone is tested and clear
- [ ] Background applications closed
- [ ] Desktop is clean (hide personal files)

During recording:

- [ ] Speak clearly and maintain good pacing
- [ ] Show code functionality, not just talk about it
- [ ] Demonstrate actual predictions with real audio
- [ ] Explain results and visualizations
- [ ] Mention both successes and limitations

After recording:

- [ ] Review video for clarity and audio quality
- [ ] Add captions/subtitles if needed
- [ ] Export in common format (MP4, 1080p)
- [ ] Upload to Canvas/Google Drive/YouTube (unlisted)
- [ ] Add link to README.md and research report
- [ ] Test link accessibility

---

## Time Management

| Section | Time | Content |
|---------|------|---------|
| Introduction | 1:00 | Project overview, objectives |
| Code Structure | 2:00 | File organization, key functions |
| Live Demo | 3-4:00 | Training, results, predictions |
| Results Discussion | 1-2:00 | Performance, findings, applications |
| Conclusion | 1:00 | Summary, future work, links |
| **Total** | **8-10:00** | Complete demonstration |

---

## Alternative: Quick Demo Version (5 minutes)

If time is limited, focus on:

1. **Introduction (30s)** - What and why
2. **Code Overview (1min)** - Main files only
3. **Live Prediction (2min)** - Show working model
4. **Results (1min)** - Key findings
5. **Conclusion (30s)** - GitHub link

---

## Technical Notes

### Screen Recording Settings
- **Resolution:** 1920x1080 (1080p) minimum
- **Frame Rate:** 30 fps
- **Audio:** 44.1kHz, mono or stereo
- **Format:** MP4 (H.264 codec)
- **Bitrate:** 5-10 Mbps

### MATLAB Display Settings
```matlab
% Increase font size for visibility
set(0, 'DefaultAxesFontSize', 14);
set(0, 'DefaultTextFontSize', 14);

% Set figure position for full screen
set(gcf, 'Position', get(0, 'Screensize'));
```

### Recommended Recording Software
- **Windows:** OBS Studio (free), Camtasia, Windows Game Bar
- **Mac:** QuickTime, ScreenFlow, OBS Studio
- **Cross-platform:** OBS Studio, Zoom recording

---

## Upload Instructions

1. **Export video** in MP4 format
2. **Upload to**:
   - Canvas (if file size < 500MB)
   - Google Drive (share with university account)
   - YouTube (unlisted link)
3. **Add link to README**:
   ```markdown
   ðŸ“¹ **Video Demonstration**: [Watch on YouTube](your-link-here)
   ```
4. **Add link to research report**
5. **Verify link works** before submission

---

## Common Mistakes to Avoid

âŒ Don't:
- Rush through code without explaining
- Show only slides without actual demo
- Forget to demonstrate predictions
- Use too small font size
- Include long silent periods
- Show personal/unrelated content

âœ… Do:
- Balance explanation with demonstration
- Show code actually running
- Explain what's happening in real-time
- Use clear, audible narration
- Keep it concise and focused
- Test everything before recording

---

**Good luck with your video recording!**

Remember: The video is meant to complement your written report and code, showing that everything actually works. Focus on demonstration over lengthy explanations.
